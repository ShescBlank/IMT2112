{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55ad8225",
   "metadata": {},
   "source": [
    "# Ayudantía 1 - Notebook 4\n",
    "### Profesor: Elwin van 't Wout\n",
    "### Ayudante: Alberto Almuna Morales (alberto.almuna@uc.cl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "801f0f24",
   "metadata": {},
   "source": [
    "The library `joblib` provides functionality for parallel computing. In this notebook, let us look into the different parallel backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc4770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8ee2978",
   "metadata": {},
   "source": [
    "Let us create the tasks to be performed in parallel by the workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4452e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_task(n):\n",
    "    my_sum = 0\n",
    "    for m in range(n):\n",
    "        my_sum += m\n",
    "    return my_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = [delayed(my_task)(i) for i in range(40000)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e813b4a",
   "metadata": {},
   "source": [
    "The `joblib` library has different parallel backends that perform can perform the parallel computations. By default, the `loky` backend is used, which is based on the *multiprocessing* model, creating different Python processes and assigning tasks to each of these processes. Alternatively, the `threading` backend is based on the *multithreading* model, creating different threads within the same process. Generally speaking, creating and managing processes requires more overhead than threads, but is more robust and reliable since there will be no race conditions.\n",
    "\n",
    "Since all tasks in this tutorial are independent, there is no risk of ```race conditions``` and both backends can be used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "965b0be2",
   "metadata": {},
   "source": [
    "When performing the parallel tasks, look in the *Activity Monitor* or *Task Manager* to see the different processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc318268",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 4\n",
    "batch_size = 1000\n",
    "verbose = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6db8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=n_jobs, batch_size=batch_size, verbose=verbose, backend='loky') as parallel_pool:\n",
    "    parallel_results = parallel_pool(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d167e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=n_jobs, batch_size=batch_size, verbose=verbose, backend='threading') as parallel_pool:\n",
    "    parallel_results = parallel_pool(tasks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aecec31b",
   "metadata": {},
   "source": [
    "The efficiency of each backend strongly depends on the specific arquitecture of the computer and the tasks to be performed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48fa7418",
   "metadata": {},
   "source": [
    "Instead of specifying the the backend explicitly, one can also nudge `joblib` into using multiprocessing or multithreading by specifying ```prefer='processes'``` or ```prefer='threading'``` when creating the `Parallel` object.\n",
    "\n",
    "For testing purposes, it can be useful to force sequential code by using ```backend='sequential'```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b6bfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Parallel(n_jobs=n_jobs, batch_size=batch_size, verbose=verbose, backend='sequential') as parallel_pool:\n",
    "    parallel_results = parallel_pool(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e57e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación secuencial directa:\n",
    "\n",
    "import time as tm\n",
    "\n",
    "ti = tm.time()\n",
    "sequential_result = [my_task(i) for i in range(40000)]\n",
    "tf = tm.time()\n",
    "\n",
    "print(tf-ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932df19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7600a12950a547366bb7a6732117e300ffd26224351912980486e1126c5d0f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
